{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0            1         2  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                   3  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"twitter_training.csv\", header=None)\n",
    "val_df = pd.read_csv(\"twitter_validation.csv\", header=None)\n",
    "\n",
    "print(train_df.head())  # Check the first few rows\n",
    "\n",
    "\n",
    "# Check dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment                                             Review\n",
      "0  Positive  im getting on borderlands and i will murder yo...\n",
      "1  Positive  I am coming to the borders and I will kill you...\n",
      "2  Positive  im getting on borderlands and i will kill you ...\n",
      "3  Positive  im coming on borderlands and i will murder you...\n",
      "4  Positive  im getting on borderlands 2 and i will murder ...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with correct column names\n",
    "train_df = pd.read_csv(\"twitter_training.csv\", header=None, names=[\"ID\", \"Product\", \"Sentiment\", \"Review\"])\n",
    "val_df = pd.read_csv(\"twitter_validation.csv\", header=None, names=[\"ID\", \"Product\", \"Sentiment\", \"Review\"])\n",
    "\n",
    "# Drop unnecessary columns (ID and Product)\n",
    "train_df = train_df[[\"Sentiment\", \"Review\"]]\n",
    "val_df = val_df[[\"Sentiment\", \"Review\"]]\n",
    "\n",
    "print(train_df.head())  # Verify if the columns are correct now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Sentiment Distribution:\n",
      " Sentiment\n",
      "Negative      22358\n",
      "Positive      20655\n",
      "Neutral       18108\n",
      "Irrelevant    12875\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Data Sentiment Distribution:\n",
      " Sentiment\n",
      "Neutral       285\n",
      "Positive      277\n",
      "Negative      266\n",
      "Irrelevant    172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each sentiment in training data\n",
    "sentiment_counts_train = train_df[\"Sentiment\"].value_counts()\n",
    "\n",
    "# Count occurrences of each sentiment in validation data\n",
    "sentiment_counts_val = val_df[\"Sentiment\"].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Training Data Sentiment Distribution:\\n\", sentiment_counts_train)\n",
    "print(\"\\nValidation Data Sentiment Distribution:\\n\", sentiment_counts_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment                                             Review\n",
      "0  Positive  im getting on borderlands and i will murder yo...\n",
      "1  Positive  i am coming to the borders and i will kill you...\n",
      "2  Positive  im getting on borderlands and i will kill you all\n",
      "3  Positive  im coming on borderlands and i will murder you...\n",
      "4  Positive  im getting on borderlands and i will murder yo...\n",
      "    Sentiment                                             Review\n",
      "0  Irrelevant  i mentioned on facebook that i was struggling ...\n",
      "1     Neutral  bbc news amazon boss jeff bezos rejects claims...\n",
      "2    Negative  why do i pay for word when it functions so poo...\n",
      "3    Negative  csgo matchmaking is so full of closet hacking ...\n",
      "4     Neutral  now the president is slapping americans in the...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "        text = re.sub(r\"@\\w+|\\#\", \"\", text)  # Remove mentions/hashtags\n",
    "        text = re.sub(r\"[^a-z\\s]\", \"\", text)  # Remove special characters and numbers\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    else:\n",
    "        text = \"\"  # Handle NaN cases\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df[\"Review\"] = train_df[\"Review\"].apply(preprocess_text)\n",
    "val_df[\"Review\"] = val_df[\"Review\"].apply(preprocess_text)\n",
    "\n",
    "# Check data after cleaning\n",
    "print(train_df.head())\n",
    "print(val_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (73996, 5000)\n",
      "Shape of X_val: (1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limits to 5000 most important words\n",
    "\n",
    "# Fit and transform the training data, only transform the validation data\n",
    "X_train = vectorizer.fit_transform(train_df[\"Review\"])\n",
    "X_val = vectorizer.transform(val_df[\"Review\"])\n",
    "\n",
    "# Convert labels into numerical format\n",
    "y_train = train_df[\"Sentiment\"]\n",
    "y_val = val_df[\"Sentiment\"]\n",
    "\n",
    "# Check the shape of the vectorized data\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(svm_model, \"sentiment_shrey1.pkl\")\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, \"vectorizer1.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully!\n",
      "Review: I love this product! It's amazing.\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: This is the worst experience I've ever had.\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: It's okay, not great but not bad either.\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: I don't think this is relevant to the topic.\n",
      "Predicted Sentiment: Irrelevant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "svm_model = joblib.load(\"sentiment_shrey1.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer1.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer loaded successfully!\")\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    processed_text = vectorizer.transform([text])  # Convert text to features\n",
    "    prediction = svm_model.predict(processed_text)  # Get sentiment prediction\n",
    "    return prediction[0]  # Return predicted sentiment\n",
    "\n",
    "# Sample test cases\n",
    "sample_reviews = [\n",
    "    \"I love this product! It's amazing.\",  # Expected: Positive\n",
    "    \"This is the worst experience I've ever had.\",  # Expected: Negative\n",
    "    \"It's okay, not great but not bad either.\",  # Expected: Neutral\n",
    "    \"I don't think this is relevant to the topic.\",  # Expected: Irrelevant\n",
    "]\n",
    "\n",
    "# Predict sentiment for each review\n",
    "for review in sample_reviews:\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {predict_sentiment(review)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "svm_model = joblib.load(\"sentiment_shrey1.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset\n",
    "def load_dataset(name):\n",
    "    if name == \"Twitter Dataset\":\n",
    "        df = pd.read_csv(\"twitter_validation.csv\", names=[\"ID\", \"Product\", \"Sentiment\", \"Review\"])\n",
    "        df = df[[\"Sentiment\", \"Review\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(\"amazon_reviews.csv\")\n",
    "        df = df.rename(columns={\"Score\": \"Sentiment\", \"Text\": \"Review\"})\n",
    "        df = df[[\"Sentiment\", \"Review\"]]\n",
    "        sentiment_map = {1: \"Negative\", 2: \"Negative\", 3: \"Neutral\", 4: \"Positive\", 5: \"Positive\"}\n",
    "        df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_map)\n",
    "    return df\n",
    "\n",
    "# Load the validation dataset\n",
    "test_df = load_dataset(\"Twitter Dataset\")\n",
    "X_val = test_df[\"Review\"]\n",
    "y_val = test_df[\"Sentiment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your sentiment mapping\n",
    "sentiment_map = {\n",
    "    1: \"Negative\", \n",
    "    2: \"Negative\", \n",
    "    3: \"Neutral\", \n",
    "    4: \"Positive\", \n",
    "    5: \"Positive\"\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(name):\n",
    "    if name == \"Twitter Dataset\":\n",
    "        df = pd.read_csv(\"twitter_validation.csv\", names=[\"ID\", \"Product\", \"Sentiment\", \"Review\"])\n",
    "        df = df[[\"Sentiment\", \"Review\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(\"amazon_reviews.csv\")\n",
    "        df = df.rename(columns={\"Score\": \"Sentiment\", \"Text\": \"Review\"})\n",
    "        df = df[[\"Sentiment\", \"Review\"]]\n",
    "        sentiment_map = {1: \"Negative\", 2: \"Negative\", 3: \"Neutral\", 4: \"Positive\", 5: \"Positive\"}\n",
    "        # Map Sentiment and filter out unknown labels\n",
    "        df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_map)\n",
    "        \n",
    "        # Filter out rows where sentiment is NaN (invalid labels)\n",
    "        df = df.dropna(subset=[\"Sentiment\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    input_vector = vectorizer.transform([review])\n",
    "    return svm_model.predict(input_vector)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
